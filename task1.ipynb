{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check if headers are there, if they aren't add them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '/Users/adamhunter/Desktop/WedgeZipOfZips/' #kept this out of my folder that was open in cursor as it was leading to lag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unzip, standardize delimiters, null placeholders, write things back with quotes around everything to help deal with a few items that have , in them like Fruit, Granola, and Nuts or something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "import zipfile\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Delete all CSV files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        os.remove(os.path.join(directory, filename))\n",
    "\n",
    "# Unzip all ZIP files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.zip'):\n",
    "        with zipfile.ZipFile(os.path.join(directory, filename), 'r') as zip_ref:\n",
    "            zip_ref.extractall(directory)\n",
    "\n",
    "# Loop through each file in the directory\n",
    "for filename in tqdm(os.listdir(directory)):\n",
    "    # Only process .csv files\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        \n",
    "        # Determine the delimiter by looking for a semicolon in first two lines\n",
    "        with open(file_path, 'r') as file:\n",
    "            first_two_lines = [next(file) for x in range(2)]\n",
    "            delimiter = ';' if any(';' in line for line in first_two_lines) else ','\n",
    "        \n",
    "        # Read the file using the determined delimiter\n",
    "        df = pd.read_csv(file_path, delimiter=delimiter)\n",
    "        \n",
    "        # Replace all occurrences of '\\N' or 'NULL' with '' for consistency, in hindsight this would have been easier if i replaced with None\n",
    "        df.replace(['\\\\N', 'NULL', '\\\\\\\\N'], '', inplace=True)\n",
    "        \n",
    "        # Write the file out again with quotes around each value, this handles product descriptions that contain delimiters\n",
    "        df.to_csv(file_path, index=False, quoting=csv.QUOTE_ALL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add headers if they are missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the standard headers\n",
    "standard_headers = [\"datetime\", \"register_no\", \"emp_no\", \"trans_no\", \"upc\", \"description\", \"trans_type\", \"trans_subtype\", \"trans_status\", \"department\", \"quantity\", \"Scale\", \"cost\", \"unitPrice\", \"total\", \"regPrice\", \"altPrice\", \"tax\", \"taxexempt\", \"foodstamp\", \"wicable\", \"discount\", \"memDiscount\", \"discountable\", \"discounttype\", \"voided\", \"percentDiscount\", \"ItemQtty\", \"volDiscType\", \"volume\", \"VolSpecial\", \"mixMatch\", \"matched\", \"memType\", \"staff\", \"numflag\", \"itemstatus\", \"tenderstatus\", \"charflag\", \"varflag\", \"batchHeaderID\", \"local\", \"organic\", \"display\", \"receipt\", \"card_no\", \"store\", \"branch\", \"match_id\", \"trans_id\"]\n",
    "\n",
    "\n",
    "# Loop through each file in the directory\n",
    "for filename in tqdm(os.listdir(directory)):\n",
    "    # Only process .csv files\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        \n",
    "        # Read the file\n",
    "        with open(file_path, 'r') as file:\n",
    "            reader = csv.reader(file)\n",
    "            headers = next(reader, None)\n",
    "        \n",
    "        # Check if headers match the standard headers\n",
    "        if headers != standard_headers:\n",
    "            # If not, read the original content into a DataFrame\n",
    "            with open(file_path, 'r') as file:\n",
    "                df = pd.read_csv(file)  # Skip the first line\n",
    "\n",
    "            # Write the standard headers and the original content to the file, quotes help if delimiters happen to be in product descriptions\n",
    "            df.to_csv(file_path, header=standard_headers, index=False, quoting=csv.QUOTE_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the standard headers and their corresponding data types\n",
    "data_types = {\n",
    "    \"datetime\": 'datetime64[ns]', \n",
    "    \"register_no\": 'float64', \n",
    "    \"emp_no\": 'float64', \n",
    "    \"trans_no\": 'float64', \n",
    "    \"upc\": 'str', \n",
    "    \"description\": 'str', \n",
    "    \"trans_type\": 'str', \n",
    "    \"trans_subtype\": 'str', \n",
    "    \"trans_status\": 'str', \n",
    "    \"department\": 'float64', \n",
    "    \"quantity\": 'float64', \n",
    "    \"Scale\": 'float64', \n",
    "    \"cost\": 'float64', \n",
    "    \"unitPrice\": 'float64', \n",
    "    \"total\": 'float64', \n",
    "    \"regPrice\": 'float64', \n",
    "    \"altPrice\": 'float64', \n",
    "    \"tax\": 'float64', \n",
    "    \"taxexempt\": 'float64', \n",
    "    \"foodstamp\": 'float64', \n",
    "    \"wicable\": 'float64', \n",
    "    \"discount\": 'float64', \n",
    "    \"memDiscount\": 'float64', \n",
    "    \"discountable\": 'float64', \n",
    "    \"discounttype\": 'float64', \n",
    "    \"voided\": 'float64', \n",
    "    \"percentDiscount\": 'float64', \n",
    "    \"ItemQtty\": 'float64', \n",
    "    \"volDiscType\": 'float64', \n",
    "    \"volume\": 'float64', \n",
    "    \"VolSpecial\": 'float64', \n",
    "    \"mixMatch\": 'float64', \n",
    "    \"matched\": 'float64', \n",
    "    \"memType\": 'bool', \n",
    "    \"staff\": 'bool', \n",
    "    \"numflag\": 'float64', \n",
    "    \"itemstatus\": 'float64', \n",
    "    \"tenderstatus\": 'float64', \n",
    "    \"charflag\": 'str', \n",
    "    \"varflag\": 'float64', \n",
    "    \"batchHeaderID\": 'bool', \n",
    "    \"local\": 'float64', \n",
    "    \"organic\": 'float64', \n",
    "    \"display\": 'bool', \n",
    "    \"receipt\": 'float64', \n",
    "    \"card_no\": 'float64', \n",
    "    \"store\": 'float64', \n",
    "    \"branch\": 'float64', \n",
    "    \"match_id\": 'float64',\n",
    "    \"trans_id\": 'float64'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In hindsight it is possible that some of the complexity in the next cell is because of replacing 'NULL' and '\\N' with '' instead of replacing with None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "for filename in tqdm(os.listdir(directory)):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        \n",
    "        df = pd.read_csv(file_path) #throws warnings about mixed dtypes\n",
    "\n",
    "        for col, dtype in data_types.items():\n",
    "            if dtype == 'float64':\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce') #first step deals with nan\n",
    "                df[col] = df[col].astype(dtype) #second step makes things that should be int into float. trying this directly didn't deal with nan properly.\n",
    "            else:\n",
    "                df[col] = df[col].astype(dtype) #if intended dtype isn't float, convert to bool/str as appropriate\n",
    "        \n",
    "        df = df.replace({'nan': None}) #certain string columns were having null turned into 'nan' by pandas? which then turned the column into strings?\n",
    "\n",
    "        # Write the cleaned DataFrame to a new CSV file\n",
    "        cleaned_file_path = os.path.join(directory, f\"cleaned_{filename}\")\n",
    "        df.to_csv(cleaned_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "  'adamh-wedge-project-6f59b14d0763.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "uploading files, had an issue with datetimes not saving properly in csv so changing in df just before upload\n",
    "\n",
    "thread pool approach cut upload time in half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def upload_to_gbq(filename):\n",
    "    if filename.startswith('cleaned_') and filename.endswith('.csv'):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        \n",
    "        # Load the cleaned CSV file into a pandas DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "        # Extract table name from the filename\n",
    "        table_name = filename[8:-4]  # Remove the 'cleaned_' prefix and .csv extension\n",
    "\n",
    "        table_id = f'adamh-wedge-project.wedge_transactions.{table_name}'\n",
    "        \n",
    "        # Upload the DataFrame to GBQ\n",
    "        df.to_gbq(table_id, credentials=credentials, if_exists='replace')\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    list(tqdm(executor.map(upload_to_gbq, os.listdir(directory)), total=len(os.listdir(directory))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "craigslist-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
